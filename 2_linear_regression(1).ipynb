{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_cLNmryybAq",
        "colab_type": "text"
      },
      "source": [
        "Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0NQQX_aVrgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "x_train = [1,2,3]\n",
        "y_train = [1,2,3]\n",
        "w = tf.Variable(tf.random_normal([1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "hypothesis = x_train * w + b\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "  sess.run(train)\n",
        "  if step % 20 == 0:\n",
        "    print(step, sess.run(cost), sess.run(w), sess.run(b))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWMyXvyiX7yw",
        "colab_type": "text"
      },
      "source": [
        "linear regression 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pK0tmtgaB4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "X = tf.placeholder(tf.float32, shape=[None])\n",
        "Y = tf.placeholder(tf.float32, shape=[None])\n",
        "w = tf.Variable(tf.random_normal([1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "hypothesis = X * w + b\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "  cost_val, w_val, b_val, _ = sess.run([cost, w, b, train], feed_dict = {X: [1,2,3,4,5], Y:[2.1,3.1,4.1,5.1,6.1]})\n",
        "  if step % 20 == 0:\n",
        "    print(step, cost_val, w_val, b_val)\n",
        "\n",
        "\n",
        "print(sess.run(hypothesis, feed_dict={X:[5]}))\n",
        "print(sess.run(hypothesis, feed_dict={X:[2.5]}))\n",
        "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}