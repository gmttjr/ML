{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDXwa9RGwz4Q",
        "colab_type": "text"
      },
      "source": [
        "Logistic classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm0_SqB6w4Ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0],[0],[0],[1],[1],[1]]\n",
        "x = tf.placeholder(tf.float32, shape=[None,2])\n",
        "y = tf.placeholder(tf.float32, shape=[None,1])\n",
        "w = tf.Variable(tf.random_normal([2,1]), name = 'weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
        "\n",
        "hypothesis = tf.sigmoid(tf.matmul(x,w) + b)\n",
        "\n",
        "cost = -tf.reduce_mean(y * tf.log(hypothesis) + (1-y)*tf.log(1-hypothesis))\n",
        "\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
        "\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for step in range(10001):\n",
        "    cost_val, _ = sess.run([cost, train], feed_dict = {x: x_data, y: y_data})\n",
        "    if step % 200 == 0:\n",
        "      print(step, cost_val)\n",
        "\n",
        "  h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={x: x_data, y:y_data})\n",
        "  print(\"\\nHypothesis: \", h, \"\\nCorrect(Y): \", c, \"\\nAccuracy: \", a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-U_Mf_HKPpQ",
        "colab_type": "text"
      },
      "source": [
        "Multinomial Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m6SR5gaKWRh",
        "colab_type": "code",
        "outputId": "7eda01b0-e074-4261-e70c-668a9970d5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x_data = [[1,2,1,1],[2,1,3,2],[3,1,3,4],[4,1,5,5],[1,7,5,5],[1,2,5,6],[1,6,6,6],[1,7,7,7]]\n",
        "y_data = [[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]\n",
        "\n",
        "x = tf.placeholder(\"float\", [None,4])\n",
        "y = tf.placeholder(\"float\", [None,3])\n",
        "nb_classes = 3\n",
        "\n",
        "w = tf.Variable(tf.random_normal([4, nb_classes]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
        "\n",
        "hypothesis = tf.nn.softmax(tf.matmul(x,w) + b)\n",
        "\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(y* tf.log(hypothesis), axis = 1))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for step in range(2001):\n",
        "    sess.run(optimizer, feed_dict = {x:x_data, y:y_data})\n",
        "    if step % 200 == 0:\n",
        "      print(step, sess.run(cost, feed_dict={x:x_data, y:y_data}))\n",
        "  \n",
        "  a=sess.run(hypothesis, feed_dict={x:[[1,11,7,9]]})\n",
        "  print(a, sess.run(tf.arg_max(a,1)))\n",
        "\n",
        "  a11=sess.run(hypothesis, feed_dict={x:[[1,11,7,9], [1,3,4,3],[1,1,0,1]]})\n",
        "  print(a11, sess.run(tf.arg_max(a11,1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 2.5317116\n",
            "200 0.5536535\n",
            "400 0.45156804\n",
            "600 0.35848534\n",
            "800 0.27179432\n",
            "1000 0.23494332\n",
            "1200 0.21317217\n",
            "1400 0.19500089\n",
            "1600 0.17959142\n",
            "1800 0.16636056\n",
            "2000 0.15488136\n",
            "[[1.8113563e-02 9.8187929e-01 7.1639020e-06]] [1]\n",
            "[[1.8113563e-02 9.8187929e-01 7.1639024e-06]\n",
            " [7.3592943e-01 2.4627391e-01 1.7796690e-02]\n",
            " [7.8037914e-09 3.0394897e-04 9.9969602e-01]] [1 0 2]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}