{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSL6rSSg30mM",
        "colab_type": "text"
      },
      "source": [
        "XOR을 위한 텐서플로우 딥네트워크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuyYTn24-D76",
        "colab_type": "code",
        "outputId": "6599f019-067c-438a-a393-58dcbc42a5d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "x_data = np.array([[0,0],[0,1],[1,0],[1,1]], dtype=np.float32)\n",
        "y_data = np.array([[0],[1],[1],[0]], dtype=np.float32)\n",
        "\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "w = tf.Variable(tf.random_normal([2,1]), name = 'weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
        "\n",
        "hypothesis = tf.sigmoid(tf.matmul(x,w)+b)\n",
        "\n",
        "cost = -tf.reduce_mean(y*tf.log(hypothesis) + (1-y)*tf.log(1-hypothesis))\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
        "\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y),dtype=tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for step in range(10001):\n",
        "    sess.run(train, feed_dict={x:x_data, y:y_data})\n",
        "    if step % 100 == 0:\n",
        "      print(step, sess.run(cost, feed_dict={x:x_data, y:y_data}), sess.run(w))\n",
        "\n",
        "  h,c,a = sess.run([hypothesis, predicted, accuracy], feed_dict = {x:x_data,y:y_data})\n",
        "  print(\"\\nHypothesis is: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \",a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0 0.8528006 [[ 1.9683679 ]\n",
            " [-0.08142981]]\n",
            "100 0.7262683 [[ 1.0205489 ]\n",
            " [-0.11558338]]\n",
            "200 0.7051086 [[ 0.60938334]\n",
            " [-0.00380629]]\n",
            "300 0.69763803 [[0.3693146]\n",
            " [0.0407018]]\n",
            "400 0.6949121 [[0.22643553]\n",
            " [0.05071582]]\n",
            "500 0.6938702 [[0.1405417 ]\n",
            " [0.04664144]]\n",
            "600 0.6934533 [[0.08827167]\n",
            " [0.03810397]]\n",
            "700 0.69328 [[0.05605509]\n",
            " [0.02925395]]\n",
            "800 0.6932058 [[0.03595063]\n",
            " [0.02163295]]\n",
            "900 0.6931733 [[0.02325825]\n",
            " [0.01560952]]\n",
            "1000 0.6931589 [[0.01516034]\n",
            " [0.01107428]]\n",
            "1100 0.69315255 [[0.00994517]\n",
            " [0.00776234]]\n",
            "1200 0.69314957 [[0.00655905]\n",
            " [0.00539293]]\n",
            "1300 0.69314826 [[0.00434505]\n",
            " [0.0037221 ]]\n",
            "1400 0.69314766 [[0.0028889 ]\n",
            " [0.00255615]]\n",
            "1500 0.6931474 [[0.00192651]\n",
            " [0.00174873]]\n",
            "1600 0.6931473 [[0.00128785]\n",
            " [0.00119285]]\n",
            "1700 0.69314724 [[0.00086256]\n",
            " [0.00081182]]\n",
            "1800 0.6931472 [[0.00057865]\n",
            " [0.00055154]]\n",
            "1900 0.6931472 [[0.00038868]\n",
            " [0.00037421]]\n",
            "2000 0.6931472 [[0.00026132]\n",
            " [0.00025359]]\n",
            "2100 0.6931472 [[0.00017583]\n",
            " [0.0001717 ]]\n",
            "2200 0.6931472 [[0.00011838]\n",
            " [0.00011618]]\n",
            "2300 0.6931472 [[7.974860e-05]\n",
            " [7.856835e-05]]\n",
            "2400 0.6931472 [[5.374309e-05]\n",
            " [5.310822e-05]]\n",
            "2500 0.6931472 [[3.6222304e-05]\n",
            " [3.5883964e-05]]\n",
            "2600 0.6931472 [[2.4422077e-05]\n",
            " [2.4241683e-05]]\n",
            "2700 0.6931472 [[1.6463366e-05]\n",
            " [1.6369399e-05]]\n",
            "2800 0.6931472 [[1.109597e-05]\n",
            " [1.105267e-05]]\n",
            "2900 0.6931472 [[7.4779668e-06]\n",
            " [7.4510585e-06]]\n",
            "3000 0.6931472 [[5.0371591e-06]\n",
            " [5.0236613e-06]]\n",
            "3100 0.6931472 [[3.3890851e-06]\n",
            " [3.3875090e-06]]\n",
            "3200 0.6931472 [[2.2953395e-06]\n",
            " [2.2937634e-06]]\n",
            "3300 0.6931472 [[1.5458094e-06]\n",
            " [1.5457234e-06]]\n",
            "3400 0.6931472 [[1.0391662e-06]\n",
            " [1.0390803e-06]]\n",
            "3500 0.6931471 [[6.860079e-07]\n",
            " [6.859220e-07]]\n",
            "3600 0.6931472 [[4.6696127e-07]\n",
            " [4.6687532e-07]]\n",
            "3700 0.6931472 [[3.1794909e-07]\n",
            " [3.1786314e-07]]\n",
            "3800 0.69314724 [[1.9873934e-07]\n",
            " [1.9865340e-07]]\n",
            "3900 0.6931472 [[1.4807520e-07]\n",
            " [1.4798925e-07]]\n",
            "4000 0.6931472 [[1.2274313e-07]\n",
            " [1.2265718e-07]]\n",
            "4100 0.6931472 [[9.8901282e-08]\n",
            " [9.8815335e-08]]\n",
            "4200 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "4300 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "4400 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "4500 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "4600 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "4700 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "4800 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "4900 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "5000 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "5100 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "5200 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "5300 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "5400 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "5500 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "5600 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "5700 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "5800 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "5900 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "6000 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "6100 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "6200 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "6300 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "6400 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "6500 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "6600 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "6700 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "6800 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "6900 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "7000 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "7100 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "7200 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "7300 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "7400 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "7500 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "7600 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "7700 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "7800 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "7900 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "8000 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "8100 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "8200 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "8300 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "8400 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "8500 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "8600 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "8700 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "8800 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "8900 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "9000 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "9100 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "9200 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "9300 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "9400 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "9500 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "9600 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "9700 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "9800 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "9900 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "10000 0.6931472 [[8.847048e-08]\n",
            " [8.838453e-08]]\n",
            "\n",
            "Hypothesis is:  [[0.5]\n",
            " [0.5]\n",
            " [0.5]\n",
            " [0.5]] \n",
            "Correct:  [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]] \n",
            "Accuracy:  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt528gD9i6SF",
        "colab_type": "code",
        "outputId": "f6d8270f-b583-4392-a04f-85086df7d784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "x_data = np.array([[0,0],[0,1],[1,0],[1,1]], dtype=np.float32)\n",
        "y_data = np.array([[0],[1],[1],[0]], dtype=np.float32)\n",
        "\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "#w = tf.Variable(tf.random_normal([2,1]), name = 'weight')\n",
        "#b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal([2,2]), name='weight1')\n",
        "b1 = tf.Variable(tf.random_normal([2]), name = 'bias1')\n",
        "layer1 = tf.sigmoid(tf.matmul(x, w1)+b1)\n",
        "\n",
        "w2 = tf.Variable(tf.random_normal([2,1]), name='weight2')\n",
        "b2 = tf.Variable(tf.random_normal([1]), name = 'bias2')\n",
        "hypothesis = tf.sigmoid(tf.matmul(layer1,w2)+b2)\n",
        "\n",
        "cost = -tf.reduce_mean(y*tf.log(hypothesis) + (1-y)*tf.log(1-hypothesis))\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
        "\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y),dtype=tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for step in range(10001):\n",
        "    sess.run(train, feed_dict={x:x_data, y:y_data})\n",
        "    if step % 100 == 0:\n",
        "      print(step, sess.run(cost, feed_dict={x:x_data, y:y_data}), sess.run([w1,w2]))\n",
        "\n",
        "  h,c,a = sess.run([hypothesis, predicted, accuracy], feed_dict = {x:x_data,y:y_data})\n",
        "  print(\"\\nHypothesis is: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \",a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.74644077 [array([[1.8484089 , 0.701511  ],\n",
            "       [0.148496  , 0.39920488]], dtype=float32), array([[-0.9492842 ],\n",
            "       [-0.24866489]], dtype=float32)]\n",
            "100 0.69340575 [array([[1.8349521 , 0.6992208 ],\n",
            "       [0.01362964, 0.4075764 ]], dtype=float32), array([[-0.62446225],\n",
            "       [-0.19605044]], dtype=float32)]\n",
            "200 0.6921252 [array([[ 1.8332436 ,  0.70498025],\n",
            "       [-0.09467793,  0.42353177]], dtype=float32), array([[-0.6137143 ],\n",
            "       [-0.21924254]], dtype=float32)]\n",
            "300 0.69081354 [array([[ 1.8353261 ,  0.7114334 ],\n",
            "       [-0.20487949,  0.4413776 ]], dtype=float32), array([[-0.61739135],\n",
            "       [-0.24262609]], dtype=float32)]\n",
            "400 0.6893843 [array([[ 1.8415253 ,  0.71840465],\n",
            "       [-0.3186634 ,  0.46100548]], dtype=float32), array([[-0.6325346],\n",
            "       [-0.265302 ]], dtype=float32)]\n",
            "500 0.68775463 [array([[ 1.8525373 ,  0.7257557 ],\n",
            "       [-0.4373057 ,  0.48237246]], dtype=float32), array([[-0.6595078],\n",
            "       [-0.2871921]], dtype=float32)]\n",
            "600 0.6858411 [array([[ 1.8693912,  0.7333109],\n",
            "       [-0.5617701,  0.5054545]], dtype=float32), array([[-0.69865763],\n",
            "       [-0.30823475]], dtype=float32)]\n",
            "700 0.68356395 [array([[ 1.8934505 ,  0.7408597 ],\n",
            "       [-0.69250935,  0.53025645]], dtype=float32), array([[-0.75012624],\n",
            "       [-0.32840085]], dtype=float32)]\n",
            "800 0.6808535 [array([[ 1.9263544 ,  0.74816644],\n",
            "       [-0.82930815,  0.55682176]], dtype=float32), array([[-0.81369823],\n",
            "       [-0.3477191 ]], dtype=float32)]\n",
            "900 0.6776498 [array([[ 1.9698629 ,  0.7549857 ],\n",
            "       [-0.97129804,  0.5852343 ]], dtype=float32), array([[-0.8887195 ],\n",
            "       [-0.36629418]], dtype=float32)]\n",
            "1000 0.673894 [array([[ 2.0255942 ,  0.76108134],\n",
            "       [-1.1172435 ,  0.6156127 ]], dtype=float32), array([[-0.9741723],\n",
            "       [-0.3843072]], dtype=float32)]\n",
            "1100 0.66951567 [array([[ 2.094728 ,  0.7662401],\n",
            "       [-1.2660197,  0.6480959]], dtype=float32), array([[-1.068902 ],\n",
            "       [-0.4020038]], dtype=float32)]\n",
            "1200 0.66443086 [array([[ 2.1777565,  0.7702793],\n",
            "       [-1.4170375,  0.6828308]], dtype=float32), array([[-1.1718805],\n",
            "       [-0.4196838]], dtype=float32)]\n",
            "1300 0.6585603 [array([[ 2.2743783 ,  0.77304727],\n",
            "       [-1.5703259 ,  0.7199736 ]], dtype=float32), array([[-1.2823164 ],\n",
            "       [-0.43770987]], dtype=float32)]\n",
            "1400 0.6518582 [array([[ 2.3835452,  0.7744242],\n",
            "       [-1.7262607,  0.7597081]], dtype=float32), array([[-1.3995609 ],\n",
            "       [-0.45653373]], dtype=float32)]\n",
            "1500 0.6443375 [array([[ 2.5036223,  0.7743202],\n",
            "       [-1.8851143,  0.8022678]], dtype=float32), array([[-1.5228837 ],\n",
            "       [-0.47672445]], dtype=float32)]\n",
            "1600 0.6360786 [array([[ 2.6325746,  0.7726764],\n",
            "       [-2.0467036,  0.8479536]], dtype=float32), array([[-1.6512781],\n",
            "       [-0.4989809]], dtype=float32)]\n",
            "1700 0.6272222 [array([[ 2.7681544 ,  0.76946735],\n",
            "       [-2.2102697 ,  0.89714575]], dtype=float32), array([[-1.7833917 ],\n",
            "       [-0.52412134]], dtype=float32)]\n",
            "1800 0.61794776 [array([[ 2.9080555 ,  0.7647019 ],\n",
            "       [-2.3745902 ,  0.95029837]], dtype=float32), array([[-1.9175979 ],\n",
            "       [-0.55305153]], dtype=float32)]\n",
            "1900 0.60844713 [array([[ 3.0500488 ,  0.75842255],\n",
            "       [-2.5382147 ,  1.0079273 ]], dtype=float32), array([[-2.0521584 ],\n",
            "       [-0.58671814]], dtype=float32)]\n",
            "2000 0.5988966 [array([[ 3.1920934,  0.7506992],\n",
            "       [-2.6997287,  1.0705845]], dtype=float32), array([[-2.1854107 ],\n",
            "       [-0.62605476]], dtype=float32)]\n",
            "2100 0.5894369 [array([[ 3.3324258,  0.7416177],\n",
            "       [-2.8579416,  1.1388252]], dtype=float32), array([[-2.3159242],\n",
            "       [-0.6719216]], dtype=float32)]\n",
            "2200 0.58016264 [array([[ 3.4696124,  0.7312628],\n",
            "       [-3.0119905,  1.2131596]], dtype=float32), array([[-2.4425857],\n",
            "       [-0.7250491]], dtype=float32)]\n",
            "2300 0.57112145 [array([[ 3.6025596,  0.7196948],\n",
            "       [-3.1613672,  1.2939874]], dtype=float32), array([[-2.5646439],\n",
            "       [-0.7859805]], dtype=float32)]\n",
            "2400 0.5623226 [array([[ 3.730492  ,  0.70693004],\n",
            "       [-3.3058794 ,  1.381521  ]], dtype=float32), array([[-2.681699 ],\n",
            "       [-0.8550168]], dtype=float32)]\n",
            "2500 0.5537487 [array([[ 3.8529224 ,  0.69291735],\n",
            "       [-3.4455957 ,  1.475703  ]], dtype=float32), array([[-2.7936714 ],\n",
            "       [-0.93216515]], dtype=float32)]\n",
            "2600 0.5453709 [array([[ 3.969597  ,  0.67753637],\n",
            "       [-3.5807755 ,  1.5761365 ]], dtype=float32), array([[-2.9007626],\n",
            "       [-1.0171012]], dtype=float32)]\n",
            "2700 0.5371619 [array([[ 4.080452 ,  0.6606229],\n",
            "       [-3.7117827,  1.682049 ]], dtype=float32), array([[-3.0034015],\n",
            "       [-1.1091511]], dtype=float32)]\n",
            "2800 0.5291065 [array([[ 4.1855726 ,  0.64201593],\n",
            "       [-3.839025  ,  1.7923149 ]], dtype=float32), array([[-3.102195 ],\n",
            "       [-1.2073104]], dtype=float32)]\n",
            "2900 0.5212065 [array([[ 4.285153  ,  0.62162817],\n",
            "       [-3.962893  ,  1.9055344 ]], dtype=float32), array([[-3.1978543],\n",
            "       [-1.3103013]], dtype=float32)]\n",
            "3000 0.5134805 [array([[ 4.379466  ,  0.59949446],\n",
            "       [-4.0837197 ,  2.020165  ]], dtype=float32), array([[-3.2911227],\n",
            "       [-1.4166697]], dtype=float32)]\n",
            "3100 0.5059593 [array([[ 4.46883   ,  0.57579976],\n",
            "       [-4.2017527 ,  2.1346705 ]], dtype=float32), array([[-3.3826928],\n",
            "       [-1.5248958]], dtype=float32)]\n",
            "3200 0.49867904 [array([[ 4.5535946,  0.5508536],\n",
            "       [-4.317148 ,  2.2476513]], dtype=float32), array([[-3.473154 ],\n",
            "       [-1.6335114]], dtype=float32)]\n",
            "3300 0.49167502 [array([[ 4.6341014,  0.5250353],\n",
            "       [-4.429984 ,  2.3579366]], dtype=float32), array([[-3.562949 ],\n",
            "       [-1.7411945]], dtype=float32)]\n",
            "3400 0.48497558 [array([[ 4.710684  ,  0.49872878],\n",
            "       [-4.54027   ,  2.46463   ]], dtype=float32), array([[-3.652369 ],\n",
            "       [-1.8468314]], dtype=float32)]\n",
            "3500 0.47860056 [array([[ 4.7836494 ,  0.47226807],\n",
            "       [-4.6479797 ,  2.5671108 ]], dtype=float32), array([[-3.7415621],\n",
            "       [-1.9495509]], dtype=float32)]\n",
            "3600 0.47255936 [array([[ 4.853284  ,  0.44590327],\n",
            "       [-4.753066  ,  2.6650121 ]], dtype=float32), array([[-3.8305647],\n",
            "       [-2.0487206]], dtype=float32)]\n",
            "3700 0.46685255 [array([[ 4.9198403 ,  0.41978782],\n",
            "       [-4.855486  ,  2.758186  ]], dtype=float32), array([[-3.9193277],\n",
            "       [-2.1439266]], dtype=float32)]\n",
            "3800 0.46147352 [array([[ 4.983548  ,  0.39398205],\n",
            "       [-4.9552064 ,  2.8466308 ]], dtype=float32), array([[-4.0077515],\n",
            "       [-2.2349381]], dtype=float32)]\n",
            "3900 0.45641053 [array([[ 5.0446105 ,  0.36846584],\n",
            "       [-5.052218  ,  2.930477  ]], dtype=float32), array([[-4.0957093],\n",
            "       [-2.3216686]], dtype=float32)]\n",
            "4000 0.4516477 [array([[ 5.1032143,  0.3431544],\n",
            "       [-5.1465354,  3.0099304]], dtype=float32), array([[-4.183067 ],\n",
            "       [-2.4041371]], dtype=float32)]\n",
            "4100 0.44716716 [array([[ 5.159516  ,  0.31791335],\n",
            "       [-5.2381973 ,  3.0852416 ]], dtype=float32), array([[-4.2697015],\n",
            "       [-2.482435 ]], dtype=float32)]\n",
            "4200 0.44294953 [array([[ 5.2136693 ,  0.29257068],\n",
            "       [-5.3272653 ,  3.1566856 ]], dtype=float32), array([[-4.3555017],\n",
            "       [-2.5566993]], dtype=float32)]\n",
            "4300 0.43897557 [array([[ 5.2658157 ,  0.26692763],\n",
            "       [-5.4138165 ,  3.2245421 ]], dtype=float32), array([[-4.440383 ],\n",
            "       [-2.6270933]], dtype=float32)]\n",
            "4400 0.43522513 [array([[ 5.3160777 ,  0.24076433],\n",
            "       [-5.4979434 ,  3.2890868 ]], dtype=float32), array([[-4.5242815],\n",
            "       [-2.6937878]], dtype=float32)]\n",
            "4500 0.43167907 [array([[ 5.3645763 ,  0.21384202],\n",
            "       [-5.579753  ,  3.3505864 ]], dtype=float32), array([[-4.6071534],\n",
            "       [-2.7569566]], dtype=float32)]\n",
            "4600 0.42831755 [array([[ 5.4114203 ,  0.18590374],\n",
            "       [-5.659358  ,  3.4092927 ]], dtype=float32), array([[-4.688979 ],\n",
            "       [-2.8167646]], dtype=float32)]\n",
            "4700 0.42512092 [array([[ 5.4567146 ,  0.15667212],\n",
            "       [-5.7368774 ,  3.4654422 ]], dtype=float32), array([[-4.769755 ],\n",
            "       [-2.8733668]], dtype=float32)]\n",
            "4800 0.4220697 [array([[ 5.500556  ,  0.12584521],\n",
            "       [-5.812433  ,  3.519261  ]], dtype=float32), array([[-4.8494954],\n",
            "       [-2.926905 ]], dtype=float32)]\n",
            "4900 0.41914278 [array([[ 5.5430355 ,  0.09308766],\n",
            "       [-5.8861527 ,  3.570961  ]], dtype=float32), array([[-4.9282246],\n",
            "       [-2.977511 ]], dtype=float32)]\n",
            "5000 0.41631854 [array([[ 5.584238  ,  0.05802464],\n",
            "       [-5.958163  ,  3.6207502 ]], dtype=float32), array([[-5.0059795],\n",
            "       [-3.0253048]], dtype=float32)]\n",
            "5100 0.41357228 [array([[ 5.624244 ,  0.0202261],\n",
            "       [-6.028594 ,  3.6688292]], dtype=float32), array([[-5.0827985],\n",
            "       [-3.0703988]], dtype=float32)]\n",
            "5200 0.41087598 [array([[ 5.6631303 , -0.02080825],\n",
            "       [-6.097577  ,  3.7154005 ]], dtype=float32), array([[-5.1587234],\n",
            "       [-3.112905 ]], dtype=float32)]\n",
            "5300 0.40819585 [array([[ 5.700965  , -0.06567148],\n",
            "       [-6.165244  ,  3.7606726 ]], dtype=float32), array([[-5.2337914],\n",
            "       [-3.152939 ]], dtype=float32)]\n",
            "5400 0.40548944 [array([[ 5.7378116 , -0.11507833],\n",
            "       [-6.2317276 ,  3.8048675 ]], dtype=float32), array([[-5.3080277],\n",
            "       [-3.1906443]], dtype=float32)]\n",
            "5500 0.40270084 [array([[ 5.773729  , -0.16990538],\n",
            "       [-6.297163  ,  3.8482237 ]], dtype=float32), array([[-5.3814287],\n",
            "       [-3.2261992]], dtype=float32)]\n",
            "5600 0.39975342 [array([[ 5.8087654 , -0.23124392],\n",
            "       [-6.3616858 ,  3.8910053 ]], dtype=float32), array([[-5.453949 ],\n",
            "       [-3.2598624]], dtype=float32)]\n",
            "5700 0.39653796 [array([[ 5.8429627 , -0.30047667],\n",
            "       [-6.4254265 ,  3.933506  ]], dtype=float32), array([[-5.525464 ],\n",
            "       [-3.2920313]], dtype=float32)]\n",
            "5800 0.39289156 [array([[ 5.876349  , -0.37938476],\n",
            "       [-6.4885116 ,  3.976052  ]], dtype=float32), array([[-5.595721 ],\n",
            "       [-3.3233402]], dtype=float32)]\n",
            "5900 0.3885619 [array([[ 5.908941  , -0.47030228],\n",
            "       [-6.551054  ,  4.018989  ]], dtype=float32), array([[-5.6642394],\n",
            "       [-3.3548224]], dtype=float32)]\n",
            "6000 0.38314232 [array([[ 5.940738 , -0.5763381],\n",
            "       [-6.6131325,  4.062653 ]], dtype=float32), array([[-5.7301407],\n",
            "       [-3.3882017]], dtype=float32)]\n",
            "6100 0.3759526 [array([[ 5.971725  , -0.70169467],\n",
            "       [-6.674772  ,  4.1073174 ]], dtype=float32), array([[-5.7918377],\n",
            "       [-3.4263794]], dtype=float32)]\n",
            "6200 0.3658275 [array([[ 6.0018787, -0.8520765],\n",
            "       [-6.735889 ,  4.153094 ]], dtype=float32), array([[-5.846453 ],\n",
            "       [-3.4742203]], dtype=float32)]\n",
            "6300 0.3508162 [array([[ 6.0311995, -1.0350173],\n",
            "       [-6.7961874,  4.1998277]], dtype=float32), array([[-5.888873 ],\n",
            "       [-3.5396726]], dtype=float32)]\n",
            "6400 0.3281703 [array([[ 6.0597954, -1.2591729],\n",
            "       [-6.854982 ,  4.2471194]], dtype=float32), array([[-5.910859 ],\n",
            "       [-3.6344457]], dtype=float32)]\n",
            "6500 0.2961692 [array([[ 6.0880413, -1.5296983],\n",
            "       [-6.911014 ,  4.294697 ]], dtype=float32), array([[-5.90345 ],\n",
            "       [-3.771086]], dtype=float32)]\n",
            "6600 0.25830483 [array([[ 6.116577 , -1.837689 ],\n",
            "       [-6.962773 ,  4.3430514]], dtype=float32), array([[-5.867861],\n",
            "       [-3.953104]], dtype=float32)]\n",
            "6700 0.22223231 [array([[ 6.145944 , -2.1564493],\n",
            "       [-7.009719 ,  4.3933   ]], dtype=float32), array([[-5.8226757],\n",
            "       [-4.1677628]], dtype=float32)]\n",
            "6800 0.19251388 [array([[ 6.17613 , -2.458104],\n",
            "       [-7.052765,  4.446148]], dtype=float32), array([[-5.7878466],\n",
            "       [-4.394229 ]], dtype=float32)]\n",
            "6900 0.16936815 [array([[ 6.2067757, -2.7281682],\n",
            "       [-7.0931463,  4.5014443]], dtype=float32), array([[-5.7713027],\n",
            "       [-4.6154113]], dtype=float32)]\n",
            "7000 0.15144677 [array([[ 6.2375317, -2.9640286],\n",
            "       [-7.1315393,  4.558509 ]], dtype=float32), array([[-5.7725964],\n",
            "       [-4.8219814]], dtype=float32)]\n",
            "7100 0.13736163 [array([[ 6.2682047, -3.1687214],\n",
            "       [-7.1680956,  4.6165156]], dtype=float32), array([[-5.7886424],\n",
            "       [-5.010723 ]], dtype=float32)]\n",
            "7200 0.1260466 [array([[ 6.298654 , -3.3469388],\n",
            "       [-7.2027507,  4.674696 ]], dtype=float32), array([[-5.8161654],\n",
            "       [-5.1818037]], dtype=float32)]\n",
            "7300 0.11674718 [array([[ 6.32879  , -3.5032835],\n",
            "       [-7.235423 ,  4.7324224]], dtype=float32), array([[-5.8523817],\n",
            "       [-5.336837 ]], dtype=float32)]\n",
            "7400 0.10894187 [array([[ 6.358545 , -3.6417022],\n",
            "       [-7.2660875,  4.789217 ]], dtype=float32), array([[-5.895048 ],\n",
            "       [-5.4778557]], dtype=float32)]\n",
            "7500 0.10226931 [array([[ 6.387856 , -3.7653978],\n",
            "       [-7.2947884,  4.8447447]], dtype=float32), array([[-5.9424157],\n",
            "       [-5.606836 ]], dtype=float32)]\n",
            "7600 0.09647563 [array([[ 6.416674 , -3.8769138],\n",
            "       [-7.321622 ,  4.898785 ]], dtype=float32), array([[-5.993132],\n",
            "       [-5.725527]], dtype=float32)]\n",
            "7700 0.09137941 [array([[ 6.4449577, -3.9782615],\n",
            "       [-7.346712 ,  4.9512024]], dtype=float32), array([[-6.0461607],\n",
            "       [-5.8354154]], dtype=float32)]\n",
            "7800 0.08684772 [array([[ 6.4726744, -4.071031 ],\n",
            "       [-7.3702   ,  5.0019307]], dtype=float32), array([[-6.1006985],\n",
            "       [-5.93774  ]], dtype=float32)]\n",
            "7900 0.082781255 [array([[ 6.4998007, -4.1564903],\n",
            "       [-7.3922296,  5.050952 ]], dtype=float32), array([[-6.1561346],\n",
            "       [-6.0335197]], dtype=float32)]\n",
            "8000 0.07910449 [array([[ 6.526319 , -4.2356544],\n",
            "       [-7.412934 ,  5.0982785]], dtype=float32), array([[-6.212004],\n",
            "       [-6.123603]], dtype=float32)]\n",
            "8100 0.07575852 [array([[ 6.5522213, -4.3093534],\n",
            "       [-7.432442 ,  5.143946 ]], dtype=float32), array([[-6.267953 ],\n",
            "       [-6.2086854]], dtype=float32)]\n",
            "8200 0.07269652 [array([[ 6.577505 , -4.378261 ],\n",
            "       [-7.450869 ,  5.1880016]], dtype=float32), array([[-6.3237033],\n",
            "       [-6.2893553]], dtype=float32)]\n",
            "8300 0.069881104 [array([[ 6.602172 , -4.442938 ],\n",
            "       [-7.4683228,  5.230509 ]], dtype=float32), array([[-6.3790545],\n",
            "       [-6.366096 ]], dtype=float32)]\n",
            "8400 0.067281455 [array([[ 6.6262293, -4.503851 ],\n",
            "       [-7.484893 ,  5.2715282]], dtype=float32), array([[-6.4338527],\n",
            "       [-6.43932  ]], dtype=float32)]\n",
            "8500 0.064872175 [array([[ 6.649684, -4.561399],\n",
            "       [-7.500663,  5.311127]], dtype=float32), array([[-6.4879837],\n",
            "       [-6.5093746]], dtype=float32)]\n",
            "8600 0.06263207 [array([[ 6.672552 , -4.615916 ],\n",
            "       [-7.5157065,  5.349372 ]], dtype=float32), array([[-6.5413647],\n",
            "       [-6.576559 ]], dtype=float32)]\n",
            "8700 0.060542963 [array([[ 6.6948442, -4.66769  ],\n",
            "       [-7.5300894,  5.386327 ]], dtype=float32), array([[-6.593939 ],\n",
            "       [-6.6411304]], dtype=float32)]\n",
            "8800 0.05858951 [array([[ 6.716576 , -4.7169733],\n",
            "       [-7.5438685,  5.4220543]], dtype=float32), array([[-6.6456656],\n",
            "       [-6.703311 ]], dtype=float32)]\n",
            "8900 0.056758583 [array([[ 6.7377634, -4.763976 ],\n",
            "       [-7.5570946,  5.456615 ]], dtype=float32), array([[-6.696519],\n",
            "       [-6.763293]], dtype=float32)]\n",
            "9000 0.0550385 [array([[ 6.7584233, -4.808892 ],\n",
            "       [-7.5698137,  5.4900675]], dtype=float32), array([[-6.746485 ],\n",
            "       [-6.8212476]], dtype=float32)]\n",
            "9100 0.05341943 [array([[ 6.7785726, -4.8518867],\n",
            "       [-7.582063 ,  5.522467 ]], dtype=float32), array([[-6.7955575],\n",
            "       [-6.8773236]], dtype=float32)]\n",
            "9200 0.051892437 [array([[ 6.7982273, -4.893108 ],\n",
            "       [-7.593882 ,  5.553865 ]], dtype=float32), array([[-6.8437395],\n",
            "       [-6.931655 ]], dtype=float32)]\n",
            "9300 0.0504497 [array([[ 6.817405 , -4.932687 ],\n",
            "       [-7.6053   ,  5.5843115]], dtype=float32), array([[-6.891037],\n",
            "       [-6.984358]], dtype=float32)]\n",
            "9400 0.04908448 [array([[ 6.8361225, -4.970743 ],\n",
            "       [-7.616345 ,  5.613854 ]], dtype=float32), array([[-6.937461 ],\n",
            "       [-7.0355406]], dtype=float32)]\n",
            "9500 0.047790505 [array([[ 6.8543944, -5.007381 ],\n",
            "       [-7.627044 ,  5.6425343]], dtype=float32), array([[-6.983025 ],\n",
            "       [-7.0852966]], dtype=float32)]\n",
            "9600 0.046562385 [array([[ 6.8722377, -5.0426936],\n",
            "       [-7.6374207,  5.6703944]], dtype=float32), array([[-7.0277443],\n",
            "       [-7.133713 ]], dtype=float32)]\n",
            "9700 0.0453951 [array([[ 6.8896666, -5.076767 ],\n",
            "       [-7.6474943,  5.697473 ]], dtype=float32), array([[-7.0716367],\n",
            "       [-7.1808643]], dtype=float32)]\n",
            "9800 0.04428424 [array([[ 6.9066963, -5.1096807],\n",
            "       [-7.6572843,  5.7238073]], dtype=float32), array([[-7.1147203],\n",
            "       [-7.2268248]], dtype=float32)]\n",
            "9900 0.043225802 [array([[ 6.9233418, -5.1415043],\n",
            "       [-7.666806 ,  5.74943  ]], dtype=float32), array([[-7.1570163],\n",
            "       [-7.271656 ]], dtype=float32)]\n",
            "10000 0.04221614 [array([[ 6.939616 , -5.172303 ],\n",
            "       [-7.676078 ,  5.7743754]], dtype=float32), array([[-7.1985435],\n",
            "       [-7.3154182]], dtype=float32)]\n",
            "\n",
            "Hypothesis is:  [[0.03722328]\n",
            " [0.9549916 ]\n",
            " [0.9495487 ]\n",
            " [0.03256753]] \n",
            "Correct:  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvrikWmjkxyc",
        "colab_type": "text"
      },
      "source": [
        "Wide NN for XOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NabS3bOCkzpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "x_data = np.array([[0,0],[0,1],[1,0],[1,1]], dtype=np.float32)\n",
        "y_data = np.array([[0],[1],[1],[0]], dtype=np.float32)\n",
        "\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "#w = tf.Variable(tf.random_normal([2,1]), name = 'weight')\n",
        "#b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal([2,10]), name='weight1')\n",
        "b1 = tf.Variable(tf.random_normal([10]), name = 'bias1')\n",
        "layer1 = tf.sigmoid(tf.matmul(x, w1)+b1)\n",
        "\n",
        "w2 = tf.Variable(tf.random_normal([10,1]), name='weight2')\n",
        "b2 = tf.Variable(tf.random_normal([1]), name = 'bias2')\n",
        "hypothesis = tf.sigmoid(tf.matmul(layer1,w2)+b2)\n",
        "\n",
        "cost = -tf.reduce_mean(y*tf.log(hypothesis) + (1-y)*tf.log(1-hypothesis))\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
        "\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y),dtype=tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for step in range(10001):\n",
        "    sess.run(train, feed_dict={x:x_data, y:y_data})\n",
        "    if step % 100 == 0:\n",
        "      print(step, sess.run(cost, feed_dict={x:x_data, y:y_data}), sess.run([w1,w2]))\n",
        "\n",
        "  h,c,a = sess.run([hypothesis, predicted, accuracy], feed_dict = {x:x_data,y:y_data})\n",
        "  print(\"\\nHypothesis is: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \",a)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}