{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMwOM4sjnov3",
        "colab_type": "text"
      },
      "source": [
        "Fancy Softmax Classification :\n",
        "cross_entropy, one_hot, reshape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wAfcYvznxdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "xy = np.loadtxt('./data-04-zoo.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = xy[:,0:-1]\n",
        "y_data = xy[:,[-1]]\n",
        "\n",
        "nb_classes = 7\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 16])\n",
        "y = tf.placeholder(tf.int32, [None,1])\n",
        "y_one_hot = tf.one_hot(y,nb_classes)\n",
        "y_one_hot = tf.reshape(y_one_hot, [-1,nb_classes])\n",
        "\n",
        "w = tf.Variable(tf.random_normal([16,nb_classes]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
        "\n",
        "logits = tf.matmul(x,w) + b\n",
        "hypothesis = tf.nn.softmax(logits)\n",
        "\n",
        "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = y_one_hot)\n",
        "cost = tf.reduce_mean(cost_i)\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
        "\n",
        "prediction = tf.argmax(hypothesis, 1)\n",
        "correct_prediction = tf.equal(prediction, tf.argmax(y_one_hot,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for step in range(2000):\n",
        "    sess.run(optimizer, feed_dict={x:x_data, y:y_data})\n",
        "    if step % 100 == 0:\n",
        "      loss, acc = sess.run([cost,accuracy], feed_dict={x:x_data,y:y_data})\n",
        "      print(\"step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step,loss,acc))\n",
        "  pred = sess.run(prediction, feed_dict={x: x_data})\n",
        "  for p, y in zip(pred, y_data.flatten()):\n",
        "     print(\"[{}] Prediction: {} True Y: {}\".format(p == int(y),p,int(y)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyucyKdBrkmB",
        "colab_type": "text"
      },
      "source": [
        "training/test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSQfoh4o1PF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x_data = [[1,2,1],[1,3,2],[1,3,4],[1,5,5],[1,7,5],[1,2,5],[1,6,6],[1,7,7]]\n",
        "y_data = [[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]\n",
        "\n",
        "x_test = [[2,1,1],[3,1,2],[3,3,4]]\n",
        "y_test = [[0,0,1],[0,0,1],[0,0,1]]\n",
        "\n",
        "x=tf.placeholder(\"float\",[None,3])\n",
        "y=tf.placeholder(\"float\",[None,3])\n",
        "w=tf.Variable(tf.random_normal([3,3]))\n",
        "b=tf.Variable(tf.random_normal([3]))\n",
        "\n",
        "hypothesis = tf.nn.softmax(tf.matmul(x,w)+b)\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(hypothesis), axis=1))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
        "\n",
        "prediction = tf.arg_max(hypothesis,1)\n",
        "is_correct = tf.equal(prediction, tf.arg_max(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for step in range(201):\n",
        "    cost_val, w_val, _ = sess.run([cost, w, optimizer], feed_dict={x:x_data, y:y_data})\n",
        "    print(step, cost_val, w_val)\n",
        "  print(\"Prediction:\", sess.run(prediction, feed_dict={x:x_test}))\n",
        "  print(\"Accuracy:\", sess.run(accuracy, feed_dict={x:x_test, y:y_test}))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giqNcoL4ABYe",
        "colab_type": "text"
      },
      "source": [
        "learning rate = 1.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZpiP2qIAB6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x_data = [[1,2,1],[1,3,2],[1,3,4],[1,5,5],[1,7,5],[1,2,5],[1,6,6],[1,7,7]]\n",
        "y_data = [[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]\n",
        "\n",
        "x_test = [[2,1,1],[3,1,2],[3,3,4]]\n",
        "y_test = [[0,0,1],[0,0,1],[0,0,1]]\n",
        "\n",
        "x=tf.placeholder(\"float\",[None,3])\n",
        "y=tf.placeholder(\"float\",[None,3])\n",
        "w=tf.Variable(tf.random_normal([3,3]))\n",
        "b=tf.Variable(tf.random_normal([3]))\n",
        "\n",
        "hypothesis = tf.nn.softmax(tf.matmul(x,w)+b)\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(hypothesis), axis=1))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.5).minimize(cost)\n",
        "\n",
        "prediction = tf.arg_max(hypothesis,1)\n",
        "is_correct = tf.equal(prediction, tf.arg_max(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for step in range(201):\n",
        "    cost_val, w_val, _ = sess.run([cost, w, optimizer], feed_dict={x:x_data, y:y_data})\n",
        "    print(step, cost_val, w_val)\n",
        "  print(\"Prediction:\", sess.run(prediction, feed_dict={x:x_test}))\n",
        "  print(\"Accuracy:\", sess.run(accuracy, feed_dict={x:x_test, y:y_test}))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IAJMRlbAS50",
        "colab_type": "text"
      },
      "source": [
        "learning rate = 1e-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA4o7UdgATRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x_data = [[1,2,1],[1,3,2],[1,3,4],[1,5,5],[1,7,5],[1,2,5],[1,6,6],[1,7,7]]\n",
        "y_data = [[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]\n",
        "\n",
        "x_test = [[2,1,1],[3,1,2],[3,3,4]]\n",
        "y_test = [[0,0,1],[0,0,1],[0,0,1]]\n",
        "\n",
        "x=tf.placeholder(\"float\",[None,3])\n",
        "y=tf.placeholder(\"float\",[None,3])\n",
        "w=tf.Variable(tf.random_normal([3,3]))\n",
        "b=tf.Variable(tf.random_normal([3]))\n",
        "\n",
        "hypothesis = tf.nn.softmax(tf.matmul(x,w)+b)\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(hypothesis), axis=1))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-10).minimize(cost)\n",
        "\n",
        "prediction = tf.arg_max(hypothesis,1)\n",
        "is_correct = tf.equal(prediction, tf.arg_max(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for step in range(201):\n",
        "    cost_val, w_val, _ = sess.run([cost, w, optimizer], feed_dict={x:x_data, y:y_data})\n",
        "    print(step, cost_val, w_val)\n",
        "  print(\"Prediction:\", sess.run(prediction, feed_dict={x:x_test}))\n",
        "  print(\"Accuracy:\", sess.run(accuracy, feed_dict={x:x_test, y:y_test}))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}