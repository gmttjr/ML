{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akn_mr3fDnp4",
        "colab_type": "text"
      },
      "source": [
        "softmax classifier for MNIST : accuracy about 89%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcFJpV0DlXCw",
        "colab_type": "code",
        "outputId": "cf158717-8ded-417e-db12-0b193ca844a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.set_random_seed(777) \n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([784, 10]))\n",
        "b = tf.Variable(tf.random_normal([10]))\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "num_epochs = 15\n",
        "num_iterations = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "hypothesis = tf.matmul(X, W) + b\n",
        "\n",
        "cost = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "        logits=hypothesis, labels=tf.stop_gradient(Y)\n",
        "    )\n",
        ")\n",
        "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(hypothesis, axis=1), tf.argmax(Y, axis=1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "   \n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        avg_cost = 0\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "            _, cost_val = sess.run([train, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
        "            avg_cost += cost_val / num_iterations\n",
        "\n",
        "        print(f\"Epoch: {(epoch + 1):04d}, Cost: {avg_cost:.9f}\")\n",
        "\n",
        "    print(\"Learning Finished!\")\n",
        "\n",
        "    print(\n",
        "        \"Accuracy:\",\n",
        "        sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}),\n",
        "    )\n",
        "\n",
        "    r = random.randint(0, mnist.test.num_examples - 1)\n",
        "\n",
        "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r : r + 1], axis=1)))\n",
        "    print(\n",
        "        \"Prediction: \",\n",
        "        sess.run(\n",
        "            tf.argmax(hypothesis, axis=1), feed_dict={X: mnist.test.images[r : r + 1]}\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    plt.imshow(\n",
        "        mnist.test.images[r : r + 1].reshape(28, 28),\n",
        "        cmap=\"Greys\",\n",
        "        interpolation=\"nearest\",\n",
        "    )\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Epoch: 0001, Cost: 5.870527597\n",
            "Epoch: 0002, Cost: 1.802985958\n",
            "Epoch: 0003, Cost: 1.148753222\n",
            "Epoch: 0004, Cost: 0.904760163\n",
            "Epoch: 0005, Cost: 0.769922458\n",
            "Epoch: 0006, Cost: 0.682201275\n",
            "Epoch: 0007, Cost: 0.619571125\n",
            "Epoch: 0008, Cost: 0.572113773\n",
            "Epoch: 0009, Cost: 0.534714068\n",
            "Epoch: 0010, Cost: 0.505436317\n",
            "Epoch: 0011, Cost: 0.481393915\n",
            "Epoch: 0012, Cost: 0.460109945\n",
            "Epoch: 0013, Cost: 0.443600857\n",
            "Epoch: 0014, Cost: 0.428196668\n",
            "Epoch: 0015, Cost: 0.414990729\n",
            "Learning Finished!\n",
            "Accuracy: 0.8979\n",
            "Label:  [0]\n",
            "Prediction:  [0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDgRB2IEg/h9irCy5ZXxcRQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha0z0Z9zHVu3",
        "colab_type": "text"
      },
      "source": [
        "MNIST_NN basic model : accuracy about 95%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDCcyYnZHYoS",
        "colab_type": "code",
        "outputId": "77a86e92-6303-403d-b9e1-34f0eaa90af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.set_random_seed(777)\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal([784, 256]))\n",
        "b1 = tf.Variable(tf.random_normal([256]))\n",
        "l1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
        "\n",
        "w2 = tf.Variable(tf.random_normal([256, 256]))\n",
        "b2 = tf.Variable(tf.random_normal([256]))\n",
        "l2 = tf.nn.relu(tf.matmul(l1, W2) + b2)\n",
        "\n",
        "w3 = tf.Variable(tf.random_normal([256, 10]))\n",
        "b3 = tf.Variable(tf.random_normal([10]))\n",
        "hypothesis = tf.matmul(l2, w3) + b3\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "    logits=hypothesis, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        feed_dict = {x: batch_xs, y: batch_ys}\n",
        "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
        "        avg_cost += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning Finished!')\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print('Accuracy:', sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
        "\n",
        "r = random.randint(0, mnist.test.num_examples - 1)\n",
        "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
        "print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict={x: mnist.test.images[r:r + 1]}))\n",
        "\n",
        "plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Epoch: 0001 cost = 4.580062651\n",
            "Epoch: 0002 cost = 1.051383912\n",
            "Epoch: 0003 cost = 0.627070453\n",
            "Epoch: 0004 cost = 0.423753840\n",
            "Epoch: 0005 cost = 0.305093316\n",
            "Epoch: 0006 cost = 0.237545195\n",
            "Epoch: 0007 cost = 0.184901160\n",
            "Epoch: 0008 cost = 0.164090974\n",
            "Epoch: 0009 cost = 0.117793394\n",
            "Epoch: 0010 cost = 0.123670034\n",
            "Epoch: 0011 cost = 0.080514019\n",
            "Epoch: 0012 cost = 0.082344994\n",
            "Epoch: 0013 cost = 0.095060341\n",
            "Epoch: 0014 cost = 0.077608804\n",
            "Epoch: 0015 cost = 0.075805088\n",
            "Learning Finished!\n",
            "Accuracy: 0.9574\n",
            "Label:  [9]\n",
            "Prediction:  [9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIkk3ceaIsZC",
        "colab_type": "text"
      },
      "source": [
        "MNiST_XAVIER INITIALIZER : accuracy about 97%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fROad2VDItA2",
        "colab_type": "code",
        "outputId": "b777707f-0c70-4598-d569-5bce9ca136cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.set_random_seed(777) \n",
        "tf.reset_default_graph() #변수 초기화\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "w1 = tf.get_variable(\"W1\", shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
        "b1 = tf.Variable(tf.random_normal([256]))\n",
        "l1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
        "\n",
        "w2 = tf.get_variable(\"W2\", shape=[256, 256],initializer=tf.contrib.layers.xavier_initializer())\n",
        "b2 = tf.Variable(tf.random_normal([256]))\n",
        "l2 = tf.nn.relu(tf.matmul(l1, w2) + b2)\n",
        "\n",
        "w3 = tf.get_variable(\"W3\", shape=[256, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
        "b3 = tf.Variable(tf.random_normal([10]))\n",
        "hypothesis = tf.matmul(l2, w3) + b3\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        feed_dict = {x: batch_xs, y: batch_ys}\n",
        "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
        "        avg_cost += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning Finished!')\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print('Accuracy:', sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
        "\n",
        "r = random.randint(0, mnist.test.num_examples - 1)\n",
        "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
        "print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict={x: mnist.test.images[r:r + 1]}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Epoch: 0001 cost = 0.305121149\n",
            "Epoch: 0002 cost = 0.112256705\n",
            "Epoch: 0003 cost = 0.071980258\n",
            "Epoch: 0004 cost = 0.052765903\n",
            "Epoch: 0005 cost = 0.040416910\n",
            "Epoch: 0006 cost = 0.028990819\n",
            "Epoch: 0007 cost = 0.023480822\n",
            "Epoch: 0008 cost = 0.019599668\n",
            "Epoch: 0009 cost = 0.015838867\n",
            "Epoch: 0010 cost = 0.013948995\n",
            "Epoch: 0011 cost = 0.016161934\n",
            "Epoch: 0012 cost = 0.011546252\n",
            "Epoch: 0013 cost = 0.008653808\n",
            "Epoch: 0014 cost = 0.008328862\n",
            "Epoch: 0015 cost = 0.012454723\n",
            "Learning Finished!\n",
            "Accuracy: 0.9775\n",
            "Label:  [2]\n",
            "Prediction:  [2]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}