{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwQ00mH5_4PD",
        "colab_type": "text"
      },
      "source": [
        "MNIST_CNN_CLASS : accuracy about 99.3%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_rMP-Dp_4ox",
        "colab_type": "code",
        "outputId": "6a480b1c-ebd5-4d5c-c467-0f39c5a58a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.set_random_seed(777)\n",
        "tf.reset_default_graph() #변수 초기화\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "class Model:\n",
        "\n",
        "    def __init__(self, sess, name):\n",
        "        self.sess = sess\n",
        "        self.name = name\n",
        "        self._build_net()\n",
        "\n",
        "    def _build_net(self):\n",
        "        with tf.variable_scope(self.name):\n",
        "            self.keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "            self.x = tf.placeholder(tf.float32, [None, 784])\n",
        "            \n",
        "            x_img = tf.reshape(self.x, [-1, 28, 28, 1]) # image 28x28x1 (b/w)\n",
        "            self.y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "            # Layer1 ImgIn shape=(?, 28, 28, 1)\n",
        "            # Conv     -> (?, 28, 28, 32)\n",
        "            # Pool     -> (?, 14, 14, 32)\n",
        "            w1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
        "            l1 = tf.nn.conv2d(x_img, w1, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            l1 = tf.nn.relu(l1)\n",
        "            l1 = tf.nn.max_pool(l1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "            l1 = tf.nn.dropout(l1, keep_prob=self.keep_prob)\n",
        "            '''\n",
        "            Result:\n",
        "            After Conv2D:0, shape=(?, 28, 28, 32)\n",
        "            After Relu:0, shape=(?, 28, 28, 32)\n",
        "            After MaxPool:0, shape=(?, 14, 14, 32)\n",
        "            After dropout/mul:0, shape=(?, 14, 14, 32)\n",
        "            '''\n",
        "\n",
        "            # Layer 2 ImgIn shape=(?, 14, 14, 32)\n",
        "            # Conv      ->(?, 14, 14, 64)\n",
        "            # Pool      ->(?, 7, 7, 64)\n",
        "            w2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
        "            l2 = tf.nn.conv2d(l1, w2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            l2 = tf.nn.relu(l2)\n",
        "            l2 = tf.nn.max_pool(l2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "            l2 = tf.nn.dropout(l2, keep_prob=self.keep_prob)\n",
        "            '''\n",
        "            Result:\n",
        "            After Conv2D_1:0, shape=(?, 14, 14, 64)\n",
        "            After Relu_1:0, shape=(?, 14, 14, 64)\n",
        "            After MaxPool_1:0, shape=(?, 7, 7, 64)\n",
        "            After dropout_1/mul:0, shape=(?, 7, 7, 64)\n",
        "            '''\n",
        "\n",
        "            # Layer 3 ImgIn shape=(?, 7, 7, 64)\n",
        "            # Conv      ->(?, 7, 7, 128)\n",
        "            # Pool      ->(?, 4, 4, 128)\n",
        "            # Reshape   ->(?, 4 * 4 * 128)\n",
        "            w3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
        "            l3 = tf.nn.conv2d(l2, w3, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            l3 = tf.nn.relu(l3)\n",
        "            l3 = tf.nn.max_pool(l3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "            l3 = tf.nn.dropout(l3, keep_prob=self.keep_prob)\n",
        "            l3_flat = tf.reshape(l3, [-1, 128 * 4 * 4])\n",
        "            '''\n",
        "            Result:\n",
        "            After Conv2D_2:0, shape=(?, 7, 7, 128)\n",
        "            After Relu_2:0, shape=(?, 7, 7, 128)\n",
        "            After MaxPool_2:0, shape=(?, 4, 4, 128)\n",
        "            After dropout_2/mul:0, shape=(?, 4, 4, 128)\n",
        "            After Reshape_1:0, shape=(?, 2048)\n",
        "            '''\n",
        "\n",
        "            # Layer 4 FC 4x4x128 inputs -> 625 outputs\n",
        "            w4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625], initializer=tf.contrib.layers.xavier_initializer())\n",
        "            b4 = tf.Variable(tf.random_normal([625]))\n",
        "            l4 = tf.nn.relu(tf.matmul(l3_flat, w4) + b4)\n",
        "            l4 = tf.nn.dropout(l4, keep_prob=self.keep_prob)\n",
        "            '''\n",
        "            Result:\n",
        "            After Relu_3:0, shape=(?, 625)\n",
        "            After dropout_3/mul:0, shape=(?, 625)\n",
        "            '''\n",
        "\n",
        "            # L5 Final FC 625 inputs -> 10 outputs\n",
        "            w5 = tf.get_variable(\"W5\", shape=[625, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
        "            b5 = tf.Variable(tf.random_normal([10]))\n",
        "            self.logits = tf.matmul(l4, w5) + b5\n",
        "            '''\n",
        "            Result:\n",
        "            After add_1:0, shape=(?, 10), dtype=float32)\n",
        "            '''\n",
        "\n",
        "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.y))\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
        "\n",
        "        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.y, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    def predict(self, x_test, keep_prop=1.0):\n",
        "        return self.sess.run(self.logits, feed_dict={self.x: x_test, self.keep_prob: keep_prop})\n",
        "\n",
        "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
        "        return self.sess.run(self.accuracy, feed_dict={self.x: x_test, self.y: y_test, self.keep_prob: keep_prop})\n",
        "\n",
        "    def train(self, x_data, y_data, keep_prop=0.7):\n",
        "        return self.sess.run([self.cost, self.optimizer], feed_dict={self.x: x_data, self.y: y_data, self.keep_prob: keep_prop})\n",
        "\n",
        "sess = tf.Session()\n",
        "m1 = Model(sess, \"m1\")\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('Learning Started')\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        c, _ = m1.train(batch_xs, batch_ys)\n",
        "        avg_cost += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Finished')\n",
        "\n",
        "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Learning Started\n",
            "Epoch: 0001 cost = 0.401218228\n",
            "Epoch: 0002 cost = 0.093768328\n",
            "Epoch: 0003 cost = 0.066042913\n",
            "Epoch: 0004 cost = 0.060063882\n",
            "Epoch: 0005 cost = 0.050105646\n",
            "Epoch: 0006 cost = 0.044522589\n",
            "Epoch: 0007 cost = 0.042557313\n",
            "Epoch: 0008 cost = 0.037961045\n",
            "Epoch: 0009 cost = 0.036576295\n",
            "Epoch: 0010 cost = 0.034148116\n",
            "Epoch: 0011 cost = 0.031219186\n",
            "Epoch: 0012 cost = 0.028509897\n",
            "Epoch: 0013 cost = 0.029053167\n",
            "Epoch: 0014 cost = 0.026715464\n",
            "Epoch: 0015 cost = 0.026679610\n",
            "Finished\n",
            "Accuracy: 0.9928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odOfGf5rAe0P",
        "colab_type": "text"
      },
      "source": [
        "MNIST_CNN_LAYERS : accuracy about 99.3%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHfG3L5vAhGe",
        "colab_type": "code",
        "outputId": "ddce8a4b-918a-4158-de10-7050df8be3ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.set_random_seed(777)\n",
        "tf.reset_default_graph() #변수 초기화\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "class Model:\n",
        "\n",
        "    def __init__(self, sess, name):\n",
        "        self.sess = sess\n",
        "        self.name = name\n",
        "        self._build_net()\n",
        "\n",
        "    def _build_net(self):\n",
        "        with tf.variable_scope(self.name):\n",
        "            self.training = tf.placeholder(tf.bool)\n",
        "\n",
        "            self.x = tf.placeholder(tf.float32, [None, 784])\n",
        "\n",
        "            x_img = tf.reshape(self.x, [-1, 28, 28, 1])\n",
        "            self.y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "            # Convolutional Layer #1\n",
        "            conv1 = tf.layers.conv2d(inputs=x_img, filters=32, kernel_size=[3, 3],padding=\"SAME\", activation=tf.nn.relu)\n",
        "            # Pooling Layer #1\n",
        "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], padding=\"SAME\", strides=2)\n",
        "            dropout1 = tf.layers.dropout(inputs=pool1,rate=0.3, training=self.training)\n",
        "\n",
        "            # Convolutional Layer #2 and Pooling Layer #2\n",
        "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],padding=\"SAME\", activation=tf.nn.relu)\n",
        "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],padding=\"SAME\", strides=2)\n",
        "            dropout2 = tf.layers.dropout(inputs=pool2, rate=0.3, training=self.training)\n",
        "\n",
        "            # Convolutional Layer #2 and Pooling Layer #2\n",
        "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
        "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], padding=\"same\", strides=2)\n",
        "            dropout3 = tf.layers.dropout(inputs=pool3,rate=0.3, training=self.training)\n",
        "\n",
        "            # Dense Layer with Relu\n",
        "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
        "            dense4 = tf.layers.dense(inputs=flat,units=625, activation=tf.nn.relu)\n",
        "            dropout4 = tf.layers.dropout(inputs=dense4,rate=0.5, training=self.training)\n",
        "\n",
        "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
        "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
        "\n",
        "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.y))\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
        "\n",
        "        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.y, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    def predict(self, x_test, training=False):\n",
        "        return self.sess.run(self.logits,feed_dict={self.x: x_test, self.training: training})\n",
        "\n",
        "    def get_accuracy(self, x_test, y_test, training=False):\n",
        "        return self.sess.run(self.accuracy,feed_dict={self.x: x_test,self.y: y_test, self.training: training})\n",
        "\n",
        "    def train(self, x_data, y_data, training=True):\n",
        "        return self.sess.run([self.cost, self.optimizer], feed_dict={self.x: x_data, self.y: y_data, self.training: training})\n",
        "\n",
        "sess = tf.Session()\n",
        "m1 = Model(sess, \"m1\")\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('Learning Started')\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        c, _ = m1.train(batch_xs, batch_ys)\n",
        "        avg_cost += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Finished')\n",
        "\n",
        "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From <ipython-input-19-fced1b11e159>:33: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-19-fced1b11e159>:35: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "WARNING:tensorflow:From <ipython-input-19-fced1b11e159>:36: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From <ipython-input-19-fced1b11e159>:50: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "Learning Started\n",
            "Epoch: 0001 cost = 0.286512199\n",
            "Epoch: 0002 cost = 0.087843931\n",
            "Epoch: 0003 cost = 0.066050227\n",
            "Epoch: 0004 cost = 0.057555984\n",
            "Epoch: 0005 cost = 0.051219282\n",
            "Epoch: 0006 cost = 0.045764082\n",
            "Epoch: 0007 cost = 0.041590734\n",
            "Epoch: 0008 cost = 0.037859480\n",
            "Epoch: 0009 cost = 0.037435320\n",
            "Epoch: 0010 cost = 0.033222694\n",
            "Epoch: 0011 cost = 0.032709280\n",
            "Epoch: 0012 cost = 0.031441033\n",
            "Epoch: 0013 cost = 0.028789883\n",
            "Epoch: 0014 cost = 0.028018515\n",
            "Epoch: 0015 cost = 0.027397597\n",
            "Finished\n",
            "Accuracy: 0.9929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdygRJ3wBjIV",
        "colab_type": "text"
      },
      "source": [
        "MNIST_CNN_ENSEMBLES : accuracy about 99.5%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns_G8rIvBjeH",
        "colab_type": "code",
        "outputId": "313c19e1-3c41-4722-c543-ef6f77c668e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.set_random_seed(777) \n",
        "tf.reset_default_graph() #변수 초기화\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 20\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "class Model:\n",
        "\n",
        "    def __init__(self, sess, name):\n",
        "        self.sess = sess\n",
        "        self.name = name\n",
        "        self._build_net()\n",
        "\n",
        "    def _build_net(self):\n",
        "        with tf.variable_scope(self.name):\n",
        "            self.training = tf.placeholder(tf.bool)\n",
        "\n",
        "            self.x = tf.placeholder(tf.float32, [None, 784])\n",
        "\n",
        "            # img 28x28x1 (black/white), Input Layer\n",
        "            x_img = tf.reshape(self.x, [-1, 28, 28, 1])\n",
        "            self.y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "            # Convolutional Layer #1\n",
        "            conv1 = tf.layers.conv2d(inputs=x_img, filters=32, kernel_size=[3, 3],padding=\"SAME\", activation=tf.nn.relu)\n",
        "            # Pooling Layer #1\n",
        "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],padding=\"SAME\", strides=2)\n",
        "            dropout1 = tf.layers.dropout(inputs=pool1,rate=0.3, training=self.training)\n",
        "\n",
        "            # Convolutional Layer #2 and Pooling Layer #2\n",
        "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],padding=\"SAME\", activation=tf.nn.relu)\n",
        "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],padding=\"SAME\", strides=2)\n",
        "            dropout2 = tf.layers.dropout(inputs=pool2,rate=0.3, training=self.training)\n",
        "\n",
        "            # Convolutional Layer #3 and Pooling Layer #3\n",
        "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],padding=\"SAME\", activation=tf.nn.relu)\n",
        "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],padding=\"SAME\", strides=2)\n",
        "            dropout3 = tf.layers.dropout(inputs=pool3,rate=0.3, training=self.training)\n",
        "\n",
        "            # Dense Layer with Relu\n",
        "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
        "            dense4 = tf.layers.dense(inputs=flat,units=625, activation=tf.nn.relu)\n",
        "            dropout4 = tf.layers.dropout(inputs=dense4,rate=0.5, training=self.training)\n",
        "\n",
        "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
        "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
        "\n",
        "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.y))\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
        "\n",
        "        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.y, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    def predict(self, x_test, training=False):\n",
        "        return self.sess.run(self.logits,feed_dict={self.x: x_test, self.training: training})\n",
        "\n",
        "    def get_accuracy(self, x_test, y_test, training=False):\n",
        "        return self.sess.run(self.accuracy,feed_dict={self.x: x_test,self.y: y_test, self.training: training})\n",
        "\n",
        "    def train(self, x_data, y_data, training=True):\n",
        "        return self.sess.run([self.cost, self.optimizer], feed_dict={self.x: x_data, self.y: y_data, self.training: training})\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "models = []\n",
        "num_models = 2\n",
        "for m in range(num_models):\n",
        "    models.append(Model(sess, \"model\" + str(m)))\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('Learning Started')\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost_list = np.zeros(len(models))\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "\n",
        "        for m_idx, m in enumerate(models):\n",
        "            c, _ = m.train(batch_xs, batch_ys)\n",
        "            avg_cost_list[m_idx] += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n",
        "\n",
        "print('Finished')\n",
        "\n",
        "test_size = len(mnist.test.labels)\n",
        "predictions = np.zeros([test_size, 10])\n",
        "for m_idx, m in enumerate(models):\n",
        "    print(m_idx, 'Accuracy:', m.get_accuracy(mnist.test.images, mnist.test.labels))\n",
        "    p = m.predict(mnist.test.images)\n",
        "    predictions += p\n",
        "\n",
        "ensemble_correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
        "ensemble_accuracy = tf.reduce_mean(tf.cast(ensemble_correct_prediction, tf.float32))\n",
        "print('Ensemble accuracy:', sess.run(ensemble_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Learning Started\n",
            "Epoch: 0001 cost = [0.28585465 0.28938861]\n",
            "Epoch: 0002 cost = [0.09087616 0.08951245]\n",
            "Epoch: 0003 cost = [0.06626785 0.06888541]\n",
            "Epoch: 0004 cost = [0.05536487 0.05645393]\n",
            "Epoch: 0005 cost = [0.05237273 0.05150979]\n",
            "Epoch: 0006 cost = [0.04593779 0.04589141]\n",
            "Epoch: 0007 cost = [0.03936706 0.04024985]\n",
            "Epoch: 0008 cost = [0.03643613 0.03556717]\n",
            "Epoch: 0009 cost = [0.03475948 0.03385207]\n",
            "Epoch: 0010 cost = [0.03444355 0.03349655]\n",
            "Epoch: 0011 cost = [0.03271658 0.03139096]\n",
            "Epoch: 0012 cost = [0.03056721 0.02934574]\n",
            "Epoch: 0013 cost = [0.02890254 0.02863802]\n",
            "Epoch: 0014 cost = [0.0269985  0.02800886]\n",
            "Epoch: 0015 cost = [0.02676732 0.02515708]\n",
            "Epoch: 0016 cost = [0.02539744 0.02717334]\n",
            "Epoch: 0017 cost = [0.02388613 0.02651006]\n",
            "Epoch: 0018 cost = [0.0251159  0.02462279]\n",
            "Epoch: 0019 cost = [0.02140534 0.02439947]\n",
            "Epoch: 0020 cost = [0.02333422 0.02383025]\n",
            "Finished\n",
            "0 Accuracy: 0.994\n",
            "1 Accuracy: 0.9941\n",
            "Ensemble accuracy: 0.9948\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}